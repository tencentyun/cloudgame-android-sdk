如果你要自定义采集视频上行，可以通过 VideoCapturer 接口进行扩展。以下是完整实现步骤：
1. 创建自定义 VideoCapturer，例如 FileVideoCapturer。
2. 通过 TcrSessionConfig.Builder#enableCustomVideoCapture() 方法注入 自定义 VideoCapturer 实例。
3. 通过 TcrSession#setEnableLocalVideo(true) 开启视频上行。
4. 【可选】通过 TcrSession#setLocalVideoProfile() 控制上行视频的参数（依赖 VideoCapturer#changeCaptureFormat() 的实现）。

# 创建自定义 VideoCapturer
## **核心实现步骤**
1. **实现 `org.twebrtc.VideoCapturer` 接口**。必须实现接口中的 6 个方法，示例结构：
   ```java
   public class CustomVideoCapturer implements VideoCapturer {
       private CapturerObserver observer;
       private SurfaceTextureHelper surfaceHelper;
       // 自定义采集状态变量

       @Override
       public void initialize(SurfaceTextureHelper helper, Context context, CapturerObserver observer) {
           this.surfaceHelper = helper;
           this.observer = observer;
       }

       @Override
       public void startCapture(int width, int height, int framerate) {
           // 启动采集逻辑
       }

       @Override
       public void stopCapture() {
           // 停止采集（需阻塞直到完成）
       }

       @Override
       public void changeCaptureFormat(int width, int height, int framerate) {
           // 动态调整格式
       }

       @Override
       public void dispose() {
           // 释放资源
       }

       @Override
       public boolean isScreencast() {
           return false; // 非屏幕采集返回 false
       }
   }
   ```

2. **初始化方法 `initialize()`**
   - 保存关键对象：
     - `SurfaceTextureHelper`：用于 GPU 纹理处理（非必须，取决于采集方式）
     - `CapturerObserver`：通过其 `onFrameCaptured()` 回传视频帧
   - 典型操作：
     ```java
     void initialize(...) {
         this.capturerObserver = capturerObserver;
         // 初始化采集硬件或解码器
     }
     ```

3. **帧捕获与传递**
   - **方式 1：内存帧（CPU）**  
     ```java
     // 创建 I420 缓冲
     JavaI420Buffer buffer = JavaI420Buffer.allocate(width, height);
     // 填充 YUV 数据（从相机/文件/网络获取）
     fillBufferData(buffer);
     
     // 构造 VideoFrame
     VideoFrame frame = new VideoFrame(
         buffer, 
         0, // 旋转角度
         System.nanoTime() // 时间戳（纳秒）
     );
     
     // 传递帧
     capturerObserver.onFrameCaptured(frame);
     frame.release(); // 释放引用
     ```

   - **方式 2：纹理帧（GPU）**  
     若使用 OpenGL 纹理：
     ```java
     // 通过 SurfaceTextureHelper 创建纹理
     VideoFrame.Buffer textureBuffer = surfaceHelper.createTextureBuffer(
         width, height, 
         VideoFrame.TextureBuffer.Type.OES // 纹理类型
     );
     
     // 传递帧
     capturerObserver.onFrameCaptured(new VideoFrame(
         textureBuffer,
         0, // 旋转
         System.nanoTime()
     ));
     // 注：WebRTC 会在消费后自动释放纹理
     ```

4. **启动/停止采集 `startCapture()/stopCapture()`**
   - **启动**：根据参数启动帧生成
     ```java
     void startCapture(int width, int height, int fps) {
         // 示例：定时器驱动（实际应使用相机回调）
         timer.schedule(new TimerTask() {
             public void run() {
                 captureFrame(); // 捕获并发送帧
             }
         }, 0, 1000 / fps);
     }
     ```
   - **停止**：确保阻塞直到采集完全停止
     ```java
     void stopCapture() throws InterruptedException {
         timer.cancel();
         // 等待最后任务完成（示例）
         synchronized (lock) {
             while (isCapturing) {
                 lock.wait();
             }
         }
     }
     ```

5. **释放资源 `dispose()`**
   - 关闭所有占用资源（文件句柄/相机/网络连接）
     ```java
     void dispose() {
         mediaReader.close();
         surfaceHelper.dispose(); // 若使用纹理
     }
     ```

---

## **关键注意事项**
1. **帧格式要求**
   - **颜色空间**：仅支持 `I420` 格式（YUV 420 Planar）
   - **对齐**：宽高需为偶数
   - **时间戳**：必须使用单调时钟 `System.nanoTime()`（非 `System.currentTimeMillis()`）

2. **线程与同步**
   - `onFrameCaptured()` 可被任意线程调用
   - 停止采集（`stopCapture()`）必须保证**线程安全**并**阻塞等待**操作完成

3. **动态格式调整**
   - `changeCaptureFormat()` 用于运行时修改分辨率/帧率
   - 示例实现：
     ```java
     void changeCaptureFormat(int width, int height, int fps) {
         stopCapture();
         startCapture(width, height, fps); // 重启采集
     }
     ```

4. **性能优化**
   - **避免重复分配内存**：复用 `JavaI420Buffer` 对象池
   - **纹理加速**：优先使用 `SurfaceTextureHelper` 减少 CPU-YUV 转换开销
   - **帧率控制**：实测帧率需匹配目标值（误差 ±2fps）

---

通过实现 `VideoCapturer` 接口，开发者可将任意视频源（文件/相机/虚拟数据）接入 TcrSdk 的视频上行流。完整示例代码可参考 [GamePlayFragment.java](https://github.com/tencentyun/cloudgame-android-sdk/tree/master/TcrSdk/Demo/TcrDemo/app/src/tcrdemo/java/com/tencent/tcrdemo/gameplay/GamePlayFragment.java#L430) 和 [MyFileVideoCapturer.java](https://github.com/tencentyun/cloudgame-android-sdk/tree/master/TcrSdk/Demo/TcrDemo/app/src/tcrdemo/java/com/tencent/tcrdemo/gameplay/MyFileVideoCapturer.java)




# 附录
接口定义
```java
public interface VideoCapturer {
  /**
   * This function is used to initialize the camera thread, the android application context, and the
   * capture observer. It will be called only once and before any startCapture() request. The
   * camera thread is guaranteed to be valid until dispose() is called. If the VideoCapturer wants
   * to deliver texture frames, it should do this by rendering on the SurfaceTexture in
   * {@code surfaceTextureHelper}, register itself as a listener, and forward the frames to
   * CapturerObserver.onFrameCaptured(). The caller still has ownership of {@code
   * surfaceTextureHelper} and is responsible for making sure surfaceTextureHelper.dispose() is
   * called. This also means that the caller can reuse the SurfaceTextureHelper to initialize a new
   * VideoCapturer once the previous VideoCapturer has been disposed.
   */
  void initialize(SurfaceTextureHelper surfaceTextureHelper, Context applicationContext,
      CapturerObserver capturerObserver);

  /**
   * Start capturing frames in a format that is as close as possible to {@code width x height} and
   * {@code framerate}.
   */
  void startCapture(int width, int height, int framerate);

  /**
   * Stop capturing. This function should block until capture is actually stopped.
   */
  void stopCapture() throws InterruptedException;

  void changeCaptureFormat(int width, int height, int framerate);

  /**
   * Perform any final cleanup here. No more capturing will be done after this call.
   */
  void dispose();

  /**
   * @return true if-and-only-if this is a screen capturer.
   */
  boolean isScreencast();
}
```
